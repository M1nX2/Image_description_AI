# app.py
import streamlit as st
from transformers import pipeline
from PIL import Image

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üñºÔ∏è Image Captioning")

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø–æ–ª—É—á–∏—Ç–µ –µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏–µ!")

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"])

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
@st.cache_resource
def load_caption_model():
    return pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
caption_model = load_caption_model()

if uploaded_file:
    # –ü–æ–∫–∞–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image = Image.open(uploaded_file)
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è
    with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è..."):
        caption = caption_model(image)[0]['generated_text']
    st.success("–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")
    st.write(caption)


else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")
    


